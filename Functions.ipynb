{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9fe949d5-89d2-49a5-a2b7-a125fd920255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e770aca9-b5f0-45ca-8ce9-36addb554f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(df):\n",
    "    \"\"\"\n",
    "    Formats the dataframe, removes duplicates and fills NaN values.\n",
    "    \"\"\"\n",
    "    df.drop('Day-ahead Total Load Forecast [MW] - BZN|NL', axis=1, inplace=True)\n",
    "    df.columns = ['Time', 'Load']\n",
    "    df[['Date', 'End']] = df['Time'].str.split(' - ', expand=True)\n",
    "    df.set_index(pd.to_datetime(df['Date'], format='%d.%m.%Y %H:%M'), inplace=True)\n",
    "    df.drop(['Time', 'Date', 'End'], axis=1, inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "\n",
    "    df = df[~df.index.duplicated(keep='first')].copy()\n",
    "    df.ffill(inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fea95f04-2757-4fc9-b854-74df8ab7a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_weather_data(start_year, end_year, scaler, weather_fields, training_data=True):\n",
    "    \"\"\"\n",
    "    Imports and formats weather data for specified period (inclusive).\n",
    "    If the data is validation data, set training_data to False.\n",
    "    \"\"\"\n",
    "    weather_dict = {}\n",
    "\n",
    "    for data_year in range(start_year, end_year+1):\n",
    "        weather_dict[data_year] = pd.read_csv(f'data/weather_{data_year}.csv', low_memory=False)\n",
    "\n",
    "    weather_full = pd.concat(weather_dict.values())\n",
    "    weather_full_columns = [column.strip() for column in weather_full.columns]\n",
    "    weather_full.columns = weather_full_columns\n",
    "\n",
    "    weather_full = weather_full.map(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    weather_full.replace('', np.NaN, inplace=True)\n",
    "\n",
    "    weather_full[weather_full.select_dtypes(include='object').columns] = (\n",
    "    weather_full[weather_full.select_dtypes(include='object').columns].astype(float))\n",
    "\n",
    "    weather_full.ffill(inplace=True)\n",
    "\n",
    "    weather_full_grouped = weather_full.groupby(['YYYYMMDD', 'HH']).mean()\n",
    "\n",
    "    weather_full_grouped = pd.concat([weather_full_grouped] * 4)\n",
    "    weather_full_grouped.sort_values(by=['YYYYMMDD', 'HH'], axis=0, inplace=True)\n",
    "\n",
    "    temp_index = [pd.to_datetime(f'{start_year}-01-01 00:00:00')]\n",
    "    for i in range(len(weather_full_grouped)-1):\n",
    "        temp_index.append(temp_index[i] + pd.Timedelta('00:15:00'))\n",
    "\n",
    "    weather_full_grouped.index = pd.to_datetime(temp_index)\n",
    "\n",
    "    std_weather = StandardScaler()\n",
    "\n",
    "    if training_data:\n",
    "        weather_full_transformed = pd.DataFrame(scaler.fit_transform(weather_full_grouped),\n",
    "                                           columns=weather_full_grouped.columns,\n",
    "                                           index=weather_full_grouped.index)\n",
    "    else:\n",
    "        weather_full_transformed = pd.DataFrame(scaler.transform(weather_full_grouped),\n",
    "                                           columns=weather_full_grouped.columns,\n",
    "                                           index=weather_full_grouped.index)\n",
    "\n",
    "    weather_full_transformed = weather_full_transformed[weather_fields]\n",
    "\n",
    "    return weather_full_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b796d4c-2f1e-491e-8545-b238d6656710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weekday_holiday(df, holidays, add_weekday=False):\n",
    "    \"\"\"\n",
    "    Adds holiday days to a DataFrame. If specified, adds weekdays as well.\n",
    "    \"\"\"\n",
    "    if add_weekday:\n",
    "        df['Weekday'] = df.index.weekday\n",
    "        df = pd.get_dummies(df, columns=['Weekday'], drop_first=True)\n",
    "        df.rename(columns={old_name: new_name for old_name, new_name in zip(\n",
    "            [column for column in df.columns if 'Weekday' in column],\n",
    "            ['Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])}, inplace=True)\n",
    "\n",
    "        for col in ['Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']:\n",
    "            df[col] = df[col].astype(float)\n",
    "    \n",
    "    df['Holiday'] = pd.to_datetime(df.index.date).isin(pd.to_datetime(holidays)).astype(float)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "68c88c1e-4848-4222-802a-09943a14d071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weather_data(df_load, df_weather, weather_fields):\n",
    "    \"\"\"\n",
    "    Adds weather data based on a specified DataFrame.\n",
    "    \"\"\"\n",
    "    start_date = df_load.iloc[0].name\n",
    "\n",
    "    df_load = df_load.merge(df_weather.loc[start_date:, weather_fields],\n",
    "                           left_index=True, right_index=True)\n",
    "\n",
    "    return df_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23e7354b-9855-462e-ac47-b2b156cf0e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lagging_data(df, lag_weeks=0, lag_days=0, lag_intervals=0, ref_column='Load'):\n",
    "    \"\"\"\n",
    "    Returns a dataframe with lagging feature data equal to specified number of prior periods.\n",
    "    \"\"\"\n",
    "    # 1) add the 24-hour lagged value\n",
    "    column_values = np.array([df[ref_column].shift(96)])\n",
    "    column_names = np.array(['Load_1_day_lag'])\n",
    "    \n",
    "    #df['Load_24_hour_lag'] = df[ref_column].shift(96)\n",
    "\n",
    "    # 2) add the lagged 15-min intervals following the lagged 24-hour value\n",
    "    for interval in range(1, lag_intervals+1):\n",
    "        column_values = np.concatenate([column_values, [df[ref_column].shift(96+interval)]])\n",
    "        column_names = np.concatenate([column_names, [f'Load_24_hour_lag+{interval}']])\n",
    "\n",
    "    # 3) add the lagged daily matching values in weekly periods\n",
    "    for day in range(2, lag_weeks*7+1):\n",
    "        column_values = np.concatenate([column_values, [df[ref_column].shift(96*day)]])\n",
    "        column_names = np.concatenate([column_names, [f'Load_{day}_day_lag']])\n",
    "\n",
    "    # 4) add additional lagged daily matching values\n",
    "    for day in range(1, lag_days+1):\n",
    "        column_values = np.concatenate([column_values, [df[ref_column].shift(96*(lag_weeks*7+day))]])\n",
    "        column_names = np.concatenate([column_names, [f'Load_{lag_weeks*7+day}_day_lag']])\n",
    "                \n",
    "    df = pd.concat([df, pd.DataFrame(column_values.T, columns=column_names,\n",
    "                                         index=df.index)], axis=1)\n",
    "\n",
    "    # drop the rows that will include NaN values from shifting\n",
    "    if lag_weeks==0 and lag_days==0:\n",
    "        df.drop(df.index[:96+lag_intervals], inplace=True)\n",
    "    else:\n",
    "        df.drop(df.index[:(lag_weeks*7+lag_days)*96], inplace=True)    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2e104ad8-da86-40d5-826d-72f28814524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for splitting X_train, X_valid\n",
    "def prep_X_y(X_train, X_valid=None, ref_column='Load'):\n",
    "    \"\"\"\n",
    "    Splits X_train, X_valid into X_train, y_train, X_valid, y_valid.\n",
    "    \"\"\"\n",
    "    y_train = X_train[ref_column]\n",
    "    X_train.drop(ref_column, axis=1, inplace=True)\n",
    "\n",
    "    if X_valid is not None:\n",
    "        y_valid = X_valid[ref_column]\n",
    "        X_valid.drop(ref_column, axis=1, inplace=True)\n",
    "        return X_train, y_train, X_valid, y_valid\n",
    "    else:\n",
    "        return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31474d90-a1c6-43ac-ae3a-332a9ebbf666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(y_true, y_pred, figsize=(12, 6), title=None):\n",
    "    \"\"\"\n",
    "    Plots y_true vs y_pred, and delta graph.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(2, 1, figsize=figsize, sharex=True)\n",
    "    y_true.plot(ax=ax[0], label='Actual')\n",
    "    y_pred.plot(ax=ax[0], label='Predicted')\n",
    "    ax[0].legend()\n",
    "    ax[0].set_ylabel('Load (MW)')\n",
    "    ax[0].grid()\n",
    "\n",
    "    ax[0].set_ylim(y_true.min()//1000*1000, (y_true.max()//1000+1)*1000)\n",
    "    ax[0].set_title(title)\n",
    "\n",
    "    delta = y_pred - y_true\n",
    "    delta.plot(ax=ax[1])\n",
    "    ax[1].axhline(0)\n",
    "    ax[1].set_ylabel('Delta (MW)')\n",
    "    ax[1].grid()\n",
    "    ax[1].set_ylim(delta.min()//1000*1000, (delta.max()//1000+1)*1000)\n",
    "    plt.xlabel(None)\n",
    "    print(f'MAE: {mean_absolute_error(y_true, y_pred):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99273960-3b3e-4ac0-a6b8-ac4f72f4ce11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
